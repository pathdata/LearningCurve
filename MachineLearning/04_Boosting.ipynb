{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['labelsC2', 'g.s', 'g.p', 'g.pdm', 'g.pdsd', 'g.effr', 'g.acirc',\n",
      "       'g.sf', 'g.theta', 'g.l1',\n",
      "       ...\n",
      "       'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24'],\n",
      "      dtype='object', length=116)\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data=pd.read_csv('../datasets/testdata.csv',sep=',')\n",
    "names=data.columns\n",
    "print(names)\n",
    "\n",
    "print(len(names))\n",
    "cell_features=data.iloc[:,1:116].values\n",
    "y=data.iloc[:,0].values\n",
    "\n",
    "le=LabelEncoder()\n",
    "y_true=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelsC2\n",
      "a    1075\n",
      "b     938\n",
      "c    1508\n",
      "l     875\n",
      "o    1069\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class distribution\n",
    "print(data.groupby('labelsC2').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3825, 115)\n",
      "(1640, 115)\n",
      "(1640,)\n",
      "[2 2 1 ..., 4 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "test_size=0.3\n",
    "seed=0\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = cross_validation.train_test_split(cell_features,y_true,test_size=test_size,random_state=seed)\n",
    "\n",
    "\n",
    "#Normalize training to improve performance\n",
    "#we can use minmax scaling or standard scaler based scaling\n",
    "stdSlr = StandardScaler().fit(X_train)\n",
    "X_train = stdSlr.transform(X_train)\n",
    "\n",
    "#Normalize test dataset same as training dataset\n",
    "stdtestslr=StandardScaler().fit(X_test)\n",
    "X_test=stdtestslr.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.751370 (0.029484)\n",
      "GBM: 0.884437 (0.018675)\n"
     ]
    }
   ],
   "source": [
    "#Load Libraries\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "num_folds = 10\n",
    "num_instances=len(X_train)\n",
    "seed = 7\n",
    "\n",
    "scoring='accuracy'\n",
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append(('GBM', GradientBoostingClassifier()))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AB', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)), ('GBM', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "print(ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "cv_result=cross_validation.cross_val_score(GradientBoostingClassifier(), X_train, Y_train, cv=kfold,scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86684073  0.89817232  0.91383812  0.87206266  0.89556136  0.85863874\n",
      "  0.86649215  0.90052356  0.86910995  0.90052356]\n"
     ]
    }
   ],
   "source": [
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GBM_Clf=GradientBoostingClassifier().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble classifier score on testing dataset is: 0.881707317073\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_GBM=GBM_Clf.score(X_test,Y_test)\n",
    "print(\"Ensemble classifier score on testing dataset is:\",test_accuracy_GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do for participants:\n",
    "Compare the performance of the two boosting classifiers and report the evaluation results in terms of confusion matrix and ROC. Upload your solutions or email us your jupyter Notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
